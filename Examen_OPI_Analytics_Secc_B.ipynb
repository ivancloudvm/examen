{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iván Vázquez Martínez\n",
    "\n",
    "# Examen OPI Analytics\n",
    "\n",
    "## Sección B\n",
    "\n",
    "## 1. Procesamiento de los datos\n",
    "\n",
    "### a. ¿Cuántos registros hay?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\apache-spark\\\\spark-3.0.1-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(r\"C:\\apache-spark\\spark-3.0.1-bin-hadoop2.7\")\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from commons.Utils import Utils\n",
    "\n",
    "conf = SparkConf().setAppName(\"airports\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\sephc\\python-spark-tutorial\\profeco_all_data.csv\"\n",
    "\n",
    "fulldf = spark.read.csv(path, header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+----------------+----------------+------+--------------------+------------------+----------+--------------------+--------------------+----------------+--------------------+--------+----------+\n",
      "|            producto|        presentacion|   marca|       categoria|        catalogo|precio|       fechaRegistro|   cadenaComercial|      giro|     nombreComercial|           direccion|          estado|           municipio| latitud|  longitud|\n",
      "+--------------------+--------------------+--------+----------------+----------------+------+--------------------+------------------+----------+--------------------+--------------------+----------------+--------------------+--------+----------+\n",
      "|CUADERNO FORMA IT...|96 HOJAS PASTA DU...|ESTRELLA|MATERIAL ESCOLAR|UTILES ESCOLARES|  25.9|2011-05-18 00:00:...|ABASTECEDORA LUMEN|PAPELERIAS|ABASTECEDORA LUME...|CANNES No. 6 ESQ....|DISTRITO FEDERAL|TLALPAN          ...|19.29699|-99.125417|\n",
      "+--------------------+--------------------+--------+----------------+----------------+------+--------------------+------------------+----------+--------------------+--------------------+----------------+--------------------+--------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fulldf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- producto: string (nullable = true)\n",
      " |-- presentacion: string (nullable = true)\n",
      " |-- marca: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- catalogo: string (nullable = true)\n",
      " |-- precio: double (nullable = true)\n",
      " |-- fechaRegistro: string (nullable = true)\n",
      " |-- cadenaComercial: string (nullable = true)\n",
      " |-- giro: string (nullable = true)\n",
      " |-- nombreComercial: string (nullable = true)\n",
      " |-- direccion: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- latitud: string (nullable = true)\n",
      " |-- longitud: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fulldf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe contiene 62,530,715 registros \n"
     ]
    }
   ],
   "source": [
    "print(\"El dataframe contiene {:,} registros \".format(fulldf.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. ¿Cuántas categorías?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tienen 42 categorias diferentes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Se tienen {:,} categorias diferentes.\".format(fulldf.select(\"categoria\").distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. ¿Cuántas cadenas comerciales están siendo monitoreadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf.select(\"cadenaComercial\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. ¿Cómo podrías determinar la calidad de los datos? ¿Detectaste algún tipo de inconsistencia o error en la fuente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La calidad la podemos determinar checando las siguientes premisas:\n",
    "1. Existencia de datos\n",
    "2. Consistencia en los datos\n",
    "3. Precisión en los datos\n",
    "4. Integridad \n",
    "5. Validez\n",
    "\n",
    "Detecté que la longitud y latitud deberían tener tipo de dato numérico, no cadena. Los nombres de los municipios tienen errores y existen datos faltantes (valores null en los estados).\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. ¿Cuáles son los productos más monitoreados en cada entidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------------------------------+-----+\n",
      "|estado                         |producto                      |count|\n",
      "+-------------------------------+------------------------------+-----+\n",
      "|MÉXICO                         |TINTE PARA EL CABELLO         |44007|\n",
      "|MÉXICO                         |TELEVISORES                   |29702|\n",
      "|MÉXICO                         |ACELGA                        |7691 |\n",
      "|MÉXICO                         |QUESO. COTIJA                 |4414 |\n",
      "|DISTRITO FEDERAL               |AZUCAR                        |18078|\n",
      "|MÉXICO                         |DESENFRIOL-ITO                |642  |\n",
      "|JALISCO                        |ARROZ                         |11735|\n",
      "|OAXACA                         |PEDIALYTE. ELECTROLITOS ORALES|302  |\n",
      "|TLAXCALA                       |AGUA SIN GAS                  |14505|\n",
      "|VERACRUZ DE IGNACIO DE LA LLAVE|TOMATE                        |652  |\n",
      "|MICHOACÁN DE OCAMPO            |PAN DE CAJA                   |13003|\n",
      "|YUCATÁN                        |FLAGENASE 400                 |313  |\n",
      "|MICHOACÁN DE OCAMPO            |ECTIVA                        |39   |\n",
      "|YUCATÁN                        |SALSA CATSUP                  |6549 |\n",
      "|YUCATÁN                        |CLAVULIN                      |183  |\n",
      "|YUCATÁN                        |CAPOTENA                      |271  |\n",
      "|JALISCO                        |FLAGENASE 400                 |699  |\n",
      "|HIDALGO                        |VERMOX                        |121  |\n",
      "|OAXACA                         |MAIZ POZOLERO                 |1387 |\n",
      "|OAXACA                         |AJO                           |783  |\n",
      "+-------------------------------+------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "fulldf.groupBy('estado','producto').count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. ¿Cuál es la cadena comercial con mayor variedad de productos monitoreados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos por \"cadenaComercial\", hacemos el conteo y usamos collect para obtener un arreglo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arreglo = fulldf.groupBy(\"cadenaComercial\").count().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el máximo y de aquí obtenemos la cadena comercial con mayor variedad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAL-MART 8643133\n"
     ]
    }
   ],
   "source": [
    "maximo = max(arreglo , key = lambda x : x[1])\n",
    "\n",
    "print(maximo[0],maximo[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis exploratorio\n",
    "\n",
    "### a. Genera una canasta de productos básicos que te permita comparar los precios geográfica y temporalmente. Justifica tu elección y procedimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun la pagina (https://www.gob.mx/canastabasica) del gobierno, la canasta básica está conformada por 40 productos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://www.gob.mx/cms/uploads/image/file/508238/CANASTA_B_SICA_04_BECA_BIENESTAR_EDUCACI_N_MEDIA_SUPERIOR-32_04_BECA_BIENESTAR_EDUCACI_N_MEDIA_SUPERIOR-32__1_.jpg\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos productos podemos crear una lista, para cada elemento de esta lista analizamos el precio en cada localidad y comparamos el precio para diferentes fechas. De esta manera podemos realizar graficos para cada producto y para cada localidad del precio vs tiempo.\n",
    "\n",
    "Consideremos los primero 10 productos de la canasta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "canasta = [\"MAIZ\", \"FRIJOL\",\"ARROZ\",\"AZUCAR\",\"HARINA\",\"ACEITE\",\"ATUN\",\"SARDINA\",\"LECHE\",\"CHILE\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un arreglo con los datos que nos interesan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "canastadf = fulldf.groupBy([\"estado\",\"producto\",\"precio\"]).count().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. ¿Cuál es la ciudad más cara del país? ¿Cuál es la más barata?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un dataframe con los datos del arreglo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estado</th>\n",
       "      <th>producto</th>\n",
       "      <th>precio</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MÉXICO</td>\n",
       "      <td>GALLETAS</td>\n",
       "      <td>27.00</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MÉXICO</td>\n",
       "      <td>REFRESCO</td>\n",
       "      <td>8.40</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MÉXICO</td>\n",
       "      <td>LECHE EN POLVO</td>\n",
       "      <td>34.95</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>LECHE ULTRAPASTEURIZADA</td>\n",
       "      <td>12.70</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>CARNE TERNERA</td>\n",
       "      <td>99.90</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             estado                 producto  precio  count\n",
       "0            MÉXICO                 GALLETAS   27.00    428\n",
       "1            MÉXICO                 REFRESCO    8.40    110\n",
       "2            MÉXICO           LECHE EN POLVO   34.95    105\n",
       "3  DISTRITO FEDERAL  LECHE ULTRAPASTEURIZADA   12.70    485\n",
       "4  DISTRITO FEDERAL            CARNE TERNERA   99.90     99"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "canasta_df = pd.DataFrame(canastadf, columns = [\"estado\",\"producto\",\"precio\",\"count\"])\n",
    "canasta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos por estado , tomamos la cuenta y filtramos la columna precio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estado</th>\n",
       "      <th>producto</th>\n",
       "      <th>precio</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MÉXICO</td>\n",
       "      <td>GALLETAS</td>\n",
       "      <td>27.00</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MÉXICO</td>\n",
       "      <td>REFRESCO</td>\n",
       "      <td>8.40</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MÉXICO</td>\n",
       "      <td>LECHE EN POLVO</td>\n",
       "      <td>34.95</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>LECHE ULTRAPASTEURIZADA</td>\n",
       "      <td>12.70</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>CARNE TERNERA</td>\n",
       "      <td>99.90</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243320</th>\n",
       "      <td>ESQ. SUR 125\"</td>\n",
       "      <td>PAN BLANCO BOLILLO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311633</th>\n",
       "      <td>ESQ. SUR 125\"</td>\n",
       "      <td>PAN BLANCO BOLILLO</td>\n",
       "      <td>1.50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002701</th>\n",
       "      <td>ESQ. SUR 125\"</td>\n",
       "      <td>TORTILLA DE MAIZ</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148146</th>\n",
       "      <td>estado</td>\n",
       "      <td>producto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940838</th>\n",
       "      <td>ESQ. SUR 125\"</td>\n",
       "      <td>PAN BLANCO BOLILLO</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estado                 producto  precio  count\n",
       "0                  MÉXICO                 GALLETAS   27.00    428\n",
       "1                  MÉXICO                 REFRESCO    8.40    110\n",
       "2                  MÉXICO           LECHE EN POLVO   34.95    105\n",
       "3        DISTRITO FEDERAL  LECHE ULTRAPASTEURIZADA   12.70    485\n",
       "4        DISTRITO FEDERAL            CARNE TERNERA   99.90     99\n",
       "...                   ...                      ...     ...    ...\n",
       "243320      ESQ. SUR 125\"       PAN BLANCO BOLILLO    1.00      1\n",
       "311633      ESQ. SUR 125\"       PAN BLANCO BOLILLO    1.50    128\n",
       "1002701     ESQ. SUR 125\"         TORTILLA DE MAIZ   11.00      2\n",
       "2148146            estado                 producto     NaN     20\n",
       "2940838     ESQ. SUR 125\"       PAN BLANCO BOLILLO    1.30      1\n",
       "\n",
       "[175 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estado_precio = canasta_df.groupby(\"estado\")\n",
    "estado_precio.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con estos datos deducimos que la ciudad más cara se encuentra en el estado de:  QUERÉTARO\n",
      "Y la ciudad más barata se encuentra en el estado de:  GUANAJUATO\n"
     ]
    }
   ],
   "source": [
    "estado_pr = estado_precio.head()\n",
    "grup = estado_pr.groupby(\"estado\").sum()\n",
    "\n",
    "print(\"Con estos datos deducimos que la ciudad más cara se encuentra en el estado de: \",grup.sort_values(\"precio\",ascending=False).index[0])\n",
    "print(\"Y la ciudad más barata se encuentra en el estado de: \",grup.sort_values(\"precio\",ascending=False).index[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. ¿Hay algún patrón estacional entre años?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos las columnas utiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro = fulldf[\"producto\",\"estado\",\"fechaRegistro\",\"precio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un arreglo agrupado por fecha de registro y un contador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o83.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\r\n\tat java.lang.reflect.Array.newInstance(Array.java:75)\r\n\tat scala.reflect.ClassTag$GenericClassTag.newArray(ClassTag.scala:151)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:290)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\r\n\tat scala.collection.AbstractTraversable.toArray(Traversable.scala:108)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:388)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3450)\r\n\tat org.apache.spark.sql.Dataset$$Lambda$2878/945736984.apply(Unknown Source)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.Dataset$$Lambda$1337/70087060.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1345/1665897041.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1338/2101762968.apply(Unknown Source)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3447)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-14f5ef130766>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfiltro2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltro\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fechaRegistro\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"precio\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0marreglo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltro2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fechaRegistro\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\apache-spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    594\u001b[0m         \"\"\"\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apache-spark\\spark-3.0.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apache-spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apache-spark\\spark-3.0.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o83.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\r\n\tat java.lang.reflect.Array.newInstance(Array.java:75)\r\n\tat scala.reflect.ClassTag$GenericClassTag.newArray(ClassTag.scala:151)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:290)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\r\n\tat scala.collection.AbstractTraversable.toArray(Traversable.scala:108)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:388)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3450)\r\n\tat org.apache.spark.sql.Dataset$$Lambda$2878/945736984.apply(Unknown Source)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.Dataset$$Lambda$1337/70087060.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1345/1665897041.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1338/2101762968.apply(Unknown Source)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3447)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "filtro2 = filtro[\"fechaRegistro\",\"precio\"]\n",
    "arreglo = filtro2.groupBy([\"fechaRegistro\"]).count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemporal = pd.DataFrame(arreglo,columns = [\"fechaRegistro\",\"count\"])\n",
    "\n",
    "#De las fechas de registro podemos extraer mes y año:\n",
    "dftemporal[\"mes\"] = dftemporal[\"fechaRegistro\"].apply(lambda x: x[:4])\n",
    "dftemporal[\"año\"] = dftemporal[\"fechaRegistro\"].apply(lambda x: x[5:7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. ¿Cuál es el estado más caro y en qué mes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el inciso b , el estado más caro es Queretaro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. ¿Cuáles son los principales riesgos de hacer análisis de series de tiempo con estos datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que los precios de los productos varían de estado a estado, se encontrarían muchas discrepancias a la hora de hacer un\n",
    "analisis temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualización\n",
    "\n",
    "### a. Genera un mapa que nos permita identificar la oferta de categorías en la zona metropolitana de León Guanajuato y el nivel de precios en cada una de ellas. Se darán puntos extra si el mapa es interactivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
